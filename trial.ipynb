{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.39.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/eraparihar/Library/Python/3.11/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.1\n",
      "    Uninstalling transformers-4.39.1:\n",
      "      Successfully uninstalled transformers-4.39.1\n",
      "Successfully installed transformers-4.39.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/eraparihar/Desktop/Semester 2/SI 630/project/squad_train-v2.0.json', 'r') as file:\n",
    "    train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataset(data):\n",
    "    dataset = []\n",
    "    for entry in data['data']:\n",
    "        title = entry['title']\n",
    "        for paragraph in entry['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                q = qa['question']\n",
    "                id_ = qa['id']\n",
    "                is_impossible = qa['is_impossible']\n",
    "                answers = qa['answers'] if not is_impossible else []\n",
    "                # For each question, we will create a dictionary with the question, its context and the answers\n",
    "                dataset.append({\n",
    "                    'id': id_,\n",
    "                    'title': title,\n",
    "                    'context': context,\n",
    "                    'question': q,\n",
    "                    'is_impossible': is_impossible,\n",
    "                    'answers': [{'text': answer['text'], 'answer_start': answer['answer_start']} for answer in answers]\n",
    "                })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = convert_to_dataset(train_data)\n",
    "\n",
    "trial_data = dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '56be85543aeaaa14008c9063',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'When did Beyonce start becoming popular?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'in the late 1990s', 'answer_start': 269}]},\n",
       " {'id': '56be85543aeaaa14008c9065',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'singing and dancing', 'answer_start': 207}]},\n",
       " {'id': '56be85543aeaaa14008c9066',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': '2003', 'answer_start': 526}]},\n",
       " {'id': '56bf6b0f3aeaaa14008c9601',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'In what city and state did Beyonce  grow up? ',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'Houston, Texas', 'answer_start': 166}]},\n",
       " {'id': '56bf6b0f3aeaaa14008c9602',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'In which decade did Beyonce become famous?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'late 1990s', 'answer_start': 276}]},\n",
       " {'id': '56bf6b0f3aeaaa14008c9603',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'In what R&B group was she the lead singer?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}]},\n",
       " {'id': '56bf6b0f3aeaaa14008c9604',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'What album made her a worldwide known artist?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}]},\n",
       " {'id': '56bf6b0f3aeaaa14008c9605',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': \"Who managed the Destiny's Child group?\",\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}]},\n",
       " {'id': '56d43c5f2ccc5a1400d830a9',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': 'When did Beyoncé rise to fame?',\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'late 1990s', 'answer_start': 276}]},\n",
       " {'id': '56d43c5f2ccc5a1400d830aa',\n",
       "  'title': 'Beyoncé',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       "  'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
       "  'is_impossible': False,\n",
       "  'answers': [{'text': 'lead singer', 'answer_start': 290}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")   #.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatted_questions = ['paraphrase: ' + row['question'] + ' </s>' for row in trial_data]\n",
    "\n",
    "for item in trial_data:\n",
    "    sentence = item['question']  \n",
    "    text = \"paraphrase: \" + sentence + \" </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Encode the text input for the model\n",
    "encoding = tokenizer.encode_plus(text, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]   #.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What role did Beyoncé have in Destiny's Child?\n",
      "Paraphrase 1: What role did Beyoncé have in Destiny's Child?\n",
      "Paraphrase 2: What role did Beyoncé have in Destiny's Child?\n",
      "Paraphrase 3: What role played Beyoncé in Destiny's Child?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_masks,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        top_k=150,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences= 3\n",
    "    )\n",
    "\n",
    "    # Decode and print the paraphrases\n",
    "print(f\"Original: {sentence}\")\n",
    "for i, output in enumerate(outputs):\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"Paraphrase {i+1}: {line}\")\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(model, tokenizer, sentence, paraphrases):\n",
    "    # Tokenize and encode the original sentence and the paraphrases\n",
    "    encoded_original = tokenizer.encode_plus(sentence, return_tensors='pt')\n",
    "    original_embedding = model(**encoded_original)[0].mean(1)  # Taking the mean of the last hidden state to get a single vector\n",
    "\n",
    "    similarities = []\n",
    "    for paraphrase in paraphrases:\n",
    "        encoded_paraphrase = tokenizer.encode_plus(paraphrase, return_tensors='pt')\n",
    "        paraphrase_embedding = model(**encoded_paraphrase)[0].mean(1)\n",
    "        \n",
    "        # Calculate cosine similarity and store\n",
    "        similarity = cosine_similarity(original_embedding, paraphrase_embedding)\n",
    "        similarities.append(similarity.item())\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What are the challenges and opportunities associated with the use of renewable energy sources to meet the world's increasing energy demands?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'similarities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m paraphrases, similarities\n\u001b[1;32m     45\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the challenges and opportunities associated with the use of renewable energy sources to meet the world\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms increasing energy demands?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 47\u001b[0m paraphrases, similarities \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrase_and_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36mparaphrase_and_similarity\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     36\u001b[0m     paraphrase_similarity_dict[paraphrase] \u001b[38;5;241m=\u001b[39m similarity\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (paraphrase, similarity) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(paraphrases, \u001b[43msimilarities\u001b[49m)):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParaphrase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparaphrase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Cosine Similarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarities' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "\n",
    "embedding_model = 'all-MiniLM-L6-v2'  \n",
    "embedder = SentenceTransformer(embedding_model)\n",
    "\n",
    "def paraphrase_and_similarity(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        top_k=150,\n",
    "        top_p=2,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=10\n",
    "\n",
    "    )\n",
    "    \n",
    "    paraphrases = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "    original_embedding = embedder.encode(sentence, convert_to_tensor=True)\n",
    "    paraphrase_embeddings = embedder.encode(paraphrases, convert_to_tensor=True)\n",
    "\n",
    "    #similarities = [util.pytorch_cos_sim(original_embedding, paraphrase_embedding)[0][0].item() for paraphrase_embedding in paraphrase_embeddings]\n",
    "\n",
    "    paraphrase_similarity_dict = {}\n",
    "    for paraphrase, paraphrase_embedding in zip(paraphrases, paraphrase_embeddings):\n",
    "        similarity = util.pytorch_cos_sim(original_embedding, paraphrase_embedding)[0][0].item()\n",
    "        paraphrase_similarity_dict[paraphrase] = similarity\n",
    "\n",
    "    print(f\"Original: {sentence}\")\n",
    "    for i, (paraphrase, similarity) in enumerate(zip(paraphrases, similarities)):\n",
    "        print(f\"Paraphrase {i+1}: {paraphrase} (Cosine Similarity: {similarity})\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    return paraphrases, similarities\n",
    "\n",
    "sentence = \"What are the challenges and opportunities associated with the use of renewable energy sources to meet the world's increasing energy demands?\"\n",
    "\n",
    "paraphrases, similarities = paraphrase_and_similarity(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**work on generating more question from all that haev very high cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Paraphrases:\n",
      "What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing energy demands of the world? (Cosine Similarity: 0.986009418964386)\n",
      "How are the challenges and opportunities associated with the use of renewable energy sources to meet the increasing global energy demands? (Cosine Similarity: 0.9716543555259705)\n",
      "What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing energy demands in the world? (Cosine Similarity: 0.98566734790802)\n",
      "\n",
      "Generated Questions for Selected Paraphrases:\n",
      "Original Paraphrase: What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing energy demands of the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the global energy demands?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy resources to meet the growing energy demands of the world?\n",
      "Generated Question: Which are the challenges and opportunities that come with the use of renewable power sources to meet the growing energy demands of the world?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original Paraphrase: How are the challenges and opportunities associated with the use of renewable energy sources to meet the increasing global energy demands?\n",
      "Generated Question: How are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demand?\n",
      "Generated Question: How are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demand?\n",
      "Generated Question: How are the challenges and opportunities associated with the use of renewable energy sources to meet the increasing global energy demands?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original Paraphrase: What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing energy demands in the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the increasing demand in the world?\n",
      "Generated Question: What are the challenges and opportunities with the use of renewable energy to meet the global growing energy demands?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing energy demand in the world?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "\n",
    "embedding_model = 'all-MiniLM-L6-v2'  # or any other model you prefer\n",
    "embedder = SentenceTransformer(embedding_model)\n",
    "\n",
    "def paraphrase_and_similarity(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        top_k=150,\n",
    "        top_p=2, \n",
    "        early_stopping=True,\n",
    "        num_return_sequences=7\n",
    "    )\n",
    "    \n",
    "    paraphrases = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    original_embedding = embedder.encode(sentence, convert_to_tensor=True)\n",
    "    paraphrase_embeddings = embedder.encode(paraphrases, convert_to_tensor=True)\n",
    "\n",
    "    paraphrase_similarity_dict = {}\n",
    "    for paraphrase, paraphrase_embedding in zip(paraphrases, paraphrase_embeddings):\n",
    "        similarity = util.pytorch_cos_sim(original_embedding, paraphrase_embedding)[0][0].item()\n",
    "        paraphrase_similarity_dict[paraphrase] = similarity\n",
    "\n",
    "    selected_paraphrases = {p: s for p, s in paraphrase_similarity_dict.items() if 0.97 <= s <= 0.99}\n",
    "\n",
    "    print(\"Selected Paraphrases:\")\n",
    "    for paraphrase, similarity in selected_paraphrases.items():\n",
    "        print(f\"{paraphrase} (Cosine Similarity: {similarity})\")\n",
    "\n",
    "    generated_questions = {}\n",
    "    for paraphrase in selected_paraphrases.keys():\n",
    "        more_outputs = model.generate(\n",
    "            input_ids=tokenizer.encode(\"paraphrase: \" + paraphrase + \" </s>\", return_tensors=\"pt\"),\n",
    "            max_length=256,\n",
    "            do_sample=True,\n",
    "            top_k=200,\n",
    "            top_p=2,  \n",
    "            early_stopping=True,\n",
    "            num_return_sequences=3\n",
    "        )\n",
    "        \n",
    "        more_paraphrases = [tokenizer.decode(output, skip_special_tokens=True) for output in more_outputs]\n",
    "        generated_questions[paraphrase] = more_paraphrases\n",
    "\n",
    "    print(\"\\nGenerated Questions for Selected Paraphrases:\")\n",
    "    for paraphrase, questions in generated_questions.items():\n",
    "        print(f\"Original Paraphrase: {paraphrase}\")\n",
    "        for question in questions:\n",
    "            print(f\"Generated Question: {question}\")\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    return selected_paraphrases, generated_questions\n",
    "\n",
    "sentence = \"What are the challenges and opportunities associated with the use of renewable energy sources to meet the world's increasing energy demands?\"\n",
    "\n",
    "selected_paraphrases, generated_questions = paraphrase_and_similarity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Paraphrases:\n",
      "What are the challenges and opportunities associated with the use of renewable energy sources to meet the increasingly high energy demand of the world? (Cosine Similarity: 0.9819177985191345)\n",
      "What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demands? (Cosine Similarity: 0.9747074842453003)\n",
      "What are the challenges and opportunities associated with the use of renewable energy sources to meet the ever-changing energy demands in the world? (Cosine Similarity: 0.9765499234199524)\n",
      "\n",
      "Generated Questions for Selected Paraphrases:\n",
      "Original Paraphrase: What are the challenges and opportunities associated with the use of renewable energy sources to meet the increasingly high energy demand of the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the global energy demand ever increasing?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the increasingly high energy demand in the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the increasing energy demand of the world?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original Paraphrase: What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demands?\n",
      "Generated Question: What are the challenges and opportunities with the use of renewable energy sources to meet the growing global energy demand?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demand?\n",
      "Generated Question: Which are the challenges and opportunities associated with the use of renewable energy sources to meet the growing global energy demands?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original Paraphrase: What are the challenges and opportunities associated with the use of renewable energy sources to meet the ever-changing energy demands in the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the ever changing energy demand in the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the ever-changing energy demands in the world?\n",
      "Generated Question: What are the challenges and opportunities associated with the use of renewable energy sources to meet the ever-changing energy demands in the world?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = 'all-MiniLM-L6-v2'  # Adjust with your preference\n",
    "embedder = SentenceTransformer(embedding_model)\n",
    "\n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two tensors.\n",
    "    \"\"\"\n",
    "    tensor1_norm = tensor1 / tensor1.norm(dim=1, keepdim=True)\n",
    "    tensor2_norm = tensor2 / tensor2.norm(dim=1, keepdim=True)\n",
    "    return torch.mm(tensor1_norm, tensor2_norm.transpose(0, 1))\n",
    "\n",
    "def paraphrase_and_similarity(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'],\n",
    "                             max_length=256, do_sample=True, top_k=150, top_p=0.95,\n",
    "                             early_stopping=True, num_return_sequences=7)\n",
    "\n",
    "    paraphrases = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "    original_embedding = embedder.encode([sentence], convert_to_tensor=True)\n",
    "    paraphrase_embeddings = embedder.encode(paraphrases, convert_to_tensor=True)\n",
    "\n",
    "    similarities = cosine_similarity(original_embedding, paraphrase_embeddings).squeeze(0).tolist()\n",
    "\n",
    "    selected_paraphrases = {paraphrase: similarity for paraphrase, similarity in zip(paraphrases, similarities) if 0.97 <= similarity <= 0.99}\n",
    "\n",
    "    print(\"Selected Paraphrases:\")\n",
    "    for paraphrase, similarity in selected_paraphrases.items():\n",
    "        print(f\"{paraphrase} (Cosine Similarity: {similarity})\")\n",
    "\n",
    "    generated_questions = {}\n",
    "    for paraphrase in selected_paraphrases.keys():\n",
    "        paraphrase_input = tokenizer(\"paraphrase: \" + paraphrase + \" </s>\", return_tensors=\"pt\")\n",
    "        more_outputs = model.generate(paraphrase_input['input_ids'], max_length=256, do_sample=True,\n",
    "                                      top_k=150, top_p=0.95, early_stopping=True, num_return_sequences=3)\n",
    "\n",
    "        questions = [tokenizer.decode(output, skip_special_tokens=True) for output in more_outputs]\n",
    "        generated_questions[paraphrase] = questions\n",
    "\n",
    "    print(\"\\nGenerated Questions for Selected Paraphrases:\")\n",
    "    for paraphrase, questions in generated_questions.items():\n",
    "        print(f\"Original Paraphrase: {paraphrase}\")\n",
    "        for question in questions:\n",
    "            print(f\"Generated Question: {question}\")\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    return selected_paraphrases, generated_questions\n",
    "\n",
    "# Example usage\n",
    "sentence = \"What are the challenges and opportunities associated with the use of renewable energy sources to meet the world's increasing energy demands?\"\n",
    "selected_paraphrases, generated_questions = paraphrase_and_similarity(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/tzujohsu/SI630/Question-answer-Generation/enlarged_finetune.pickle\", \"rb\") as fp:\n",
    "    enlarged_finetune = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some scholars[note 44] use other schemes. Buddhists themselves have a variety of other schemes. Hinayana (literally \"lesser vehicle\") is used by Mahayana followers to name the family of early philosophical schools and traditions from which contemporary Theravada emerged, but as this term is rooted in the Mahayana viewpoint and can be considered derogatory, a variety of other terms are increasingly used instead, including Śrāvakayāna, Nikaya Buddhism, early Buddhist schools, sectarian Buddhism, conservative Buddhism, mainstream Buddhism and non-Mahayana Buddhism.',\n",
       " 'lesser vehicle',\n",
       " ['What does Hinayana mean in English?',\n",
       "  'What means Hinayana in English?',\n",
       "  'What does the word Hinayana mean?',\n",
       "  'What does the word Hinayana mean in English?']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlarged_finetune[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in enlarged_finetune:\n",
    "    ctx = f\"\"\"\n",
    "    answer: {i[1]}, context: {i[0]}\n",
    "    \"\"\"\n",
    "    for q in i[2]:\n",
    "        train.append({'input':ctx, 'label':q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10347"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open('qg_train.json', 'w') as file:  # The 'jsonl' or 'ndjson' extension is often used for newline-delimited JSON\n",
    "    for entry in train[:8000]:\n",
    "        json.dump(entry, file)  # Dump the dictionary as a JSON string\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open('qg_test.json', 'w') as file:  # The 'jsonl' or 'ndjson' extension is often used for newline-delimited JSON\n",
    "    for entry in train[8000:]:\n",
    "        json.dump(entry, file)  # Dump the dictionary as a JSON string\n",
    "        file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
