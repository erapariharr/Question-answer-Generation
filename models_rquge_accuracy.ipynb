{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rquge\n",
    "#!pip install transformers\n",
    "#!pip install sentencepiece\n",
    "#!pip install git+https://github.com/alirezamshi/RQUGE\n",
    "#!pip install evaluate\n",
    "#!pip install sentence-transformers\n",
    "#!pip install pandas\n",
    "#!pip install --user sentencepiece\n",
    "#!pip install git+https://github.com/alirezamshi/RQUGE\n",
    "#!pip install rouge_score absl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from evaluate import load\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/eraparihar/Desktop/Semester 2/SI 630/project/squad_train-v2.0.json', 'r') as file:\n",
    "#     train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting the format for json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_dataset(data):\n",
    "#     dataset = []\n",
    "#     for entry in data['data']:\n",
    "#         title = entry['title']\n",
    "#         for paragraph in entry['paragraphs']:\n",
    "#             context = paragraph['context']\n",
    "#             for qa in paragraph['qas']:\n",
    "#                 q = qa['question']\n",
    "#                 id_ = qa['id']\n",
    "#                 is_impossible = qa['is_impossible']\n",
    "#                 answers = qa['answers'] if not is_impossible else []\n",
    "#                 # For each question, we will create a dictionary with the question, its context and the answers\n",
    "#                 dataset.append({\n",
    "#                     'id': id_,\n",
    "#                     'title': title,\n",
    "#                     'context': context,\n",
    "#                     'question': q,\n",
    "#                     'is_impossible': is_impossible,\n",
    "#                     'answers': [{'text': answer['text'], 'answer_start': answer['answer_start']} for answer in answers]\n",
    "#                 })\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trial_data.json', 'r') as file:\n",
    "    train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial_datad = trial_data.to_dict(orient='records') # coverting df to dict\n",
    "with open('trial_data.json', 'r') as file:\n",
    "    trial_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trial_data[0:100]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input model name below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"allenai/unifiedqa-t5-large\" # can specify the model size here\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def run_model(input_string, **generator_args):\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "    res = model.generate(input_ids, **generator_args)\n",
    "    return tokenizer.batch_decode(res, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample run_model, can try using different arguments with calling the function \n",
    "# run_model(\"which is best conductor? \\\\n (a) iron (b) feather (c) wood (d) plastic\",\n",
    "#          temperature=0.9, num_return_sequences=4, num_beams=20)\n",
    "\n",
    "run_model(\"which is best conductor? \\\\n (a) iron (b) feather (c) wood (d) plastic\",\n",
    "         temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_questions = []\n",
    "contexts = []\n",
    "generated_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries: 100%|██████████| 100/100 [04:48<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for entry in tqdm(data, desc=\"Processing entries\"):\n",
    "    input_string = f\"Question: {entry['question']} Context: {entry['context']}\"\n",
    "    output = run_model(input_string, )\n",
    "    generated_answers.append(output[0])  \n",
    "    contexts.append(entry['context'])\n",
    "    generated_questions.append(entry['question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['late 1990s',\n",
       " 'singing and dancing',\n",
       " '2003',\n",
       " 'Houston, Texas',\n",
       " '1990s',\n",
       " \"Destiny's Child\",\n",
       " 'Dangerously in Love',\n",
       " 'her father, Mathew Knowles',\n",
       " 'late 1990s',\n",
       " 'lead singer',\n",
       " 'Dangerously in Love',\n",
       " '2003',\n",
       " 'five',\n",
       " 'lead singer',\n",
       " 'Dangerously in Love',\n",
       " 'acting',\n",
       " 'Jay Z',\n",
       " 'six',\n",
       " 'Dreamgirls',\n",
       " '2010',\n",
       " 'Beyoncé',\n",
       " 'Cadillac Records',\n",
       " 'June 2005',\n",
       " \"B'Day\",\n",
       " 'Dreamgirls',\n",
       " 'Jay Z',\n",
       " 'Sasha Fierce',\n",
       " 'love, relationships, and monogamy',\n",
       " 'influential',\n",
       " 'Forbes',\n",
       " '2000s',\n",
       " 'Forbes',\n",
       " 'modern-day feminist',\n",
       " '2013 and 2014',\n",
       " '118 million',\n",
       " '60 million',\n",
       " '118 million',\n",
       " '20',\n",
       " 'Forbes',\n",
       " \"Destiny's Child\",\n",
       " \"her mother's maiden name\",\n",
       " 'African-American',\n",
       " 'Methodist',\n",
       " 'Xerox',\n",
       " 'hairdresser',\n",
       " 'Solange',\n",
       " 'Joseph Broussard',\n",
       " 'Xerox',\n",
       " 'salon',\n",
       " 'Solange',\n",
       " 'Joseph Broussard',\n",
       " 'Methodist',\n",
       " 'Fredericksburg',\n",
       " 'dance instructor Darlette Johnson',\n",
       " 'Houston',\n",
       " 'dance instructor Darlette Johnson',\n",
       " \"St. John's United Methodist Church\",\n",
       " 'music magnet school',\n",
       " 'Imagine',\n",
       " 'Fredericksburg',\n",
       " 'Darlette Johnson',\n",
       " 'seven',\n",
       " \"St. John's United Methodist Church\",\n",
       " 'Arne Frager',\n",
       " \"Beyoncé's father\",\n",
       " 'Elektra Records',\n",
       " 'Arne Frager',\n",
       " '1995',\n",
       " 'Sony Music',\n",
       " 'Elektra Records',\n",
       " 'eight',\n",
       " 'eight',\n",
       " \"Girl's Tyme\",\n",
       " 'Arne Frager',\n",
       " '1995',\n",
       " 'Dwayne Wiggins',\n",
       " 'Men in Black',\n",
       " 'Say My Name',\n",
       " 'Marc Nelson',\n",
       " '1996',\n",
       " 'Book of Isaiah',\n",
       " 'Men in Black',\n",
       " 'Say My Name',\n",
       " 'Marc Nelson',\n",
       " 'Book of Isaiah',\n",
       " 'Men in Black',\n",
       " '\"No, No, No\"',\n",
       " '1999',\n",
       " 'Marc Nelson',\n",
       " 'depression',\n",
       " 'boyfriend left her',\n",
       " 'her mother',\n",
       " 'split with Luckett and Roberson',\n",
       " 'a couple of years',\n",
       " 'her mother',\n",
       " 'Farrah Franklin and Michelle Williams',\n",
       " 'Beyoncé',\n",
       " 'her mother',\n",
       " 'Farrah Franklin',\n",
       " 'Independent Women Part I']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RQUGE Score: 4.91074542760849\n"
     ]
    }
   ],
   "source": [
    "rqugescore = load(\"alirezamsh/rquge\")\n",
    "results = rqugescore.compute(generated_questions=generated_questions, contexts=contexts, answers=generated_answers)\n",
    "print(\"Mean RQUGE Score:\", results[\"mean_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial implementation for understanding\n",
    "\n",
    "# from evaluate import load\n",
    "# rqugescore = load(\"alirezamsh/rquge\")\n",
    "# generated_questions = [\"how is the weather?\"]\n",
    "# contexts = [\"the weather is sunny\"]\n",
    "# answers = [\"sunny\"]\n",
    "# results = rqugescore.compute(generated_questions=generated_questions, contexts=contexts, answers=answers)\n",
    "# print(results[\"mean_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_answers = [item['answers'][0]['text'] for item in data] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erap/.local/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/erap/.local/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/erap/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/erap/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/erap/.local/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: {'bleu': 0.6977587666643851, 'precisions': [0.87, 0.7474747474747475, 0.6428571428571429, 0.5670103092783505], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 100, 'reference_length': 100}\n",
      "METEOR Score: {'meteor': 0.74504464547986}\n",
      "ROUGE Score: {'rouge1': AggregateScore(low=Score(precision=0.972975, recall=0.9403249999999999, fmeasure=0.9469916666666668), mid=Score(precision=0.988, recall=0.97, fmeasure=0.971), high=Score(precision=1.0, recall=0.9925, fmeasure=0.9886666666666666)), 'rouge2': AggregateScore(low=Score(precision=0.5199583333333334, recall=0.5199875, fmeasure=0.5158124999999999), mid=Score(precision=0.6133333333333334, recall=0.6108333333333333, fmeasure=0.6033333333333334), high=Score(precision=0.6933333333333335, recall=0.695, fmeasure=0.685875)), 'rougeL': AggregateScore(low=Score(precision=0.971, recall=0.9399958333333333, fmeasure=0.9469916666666668), mid=Score(precision=0.988, recall=0.9688333333333334, fmeasure=0.9696666666666667), high=Score(precision=1.0, recall=0.9910083333333333, fmeasure=0.9883416666666666)), 'rougeLsum': AggregateScore(low=Score(precision=0.972, recall=0.9425, fmeasure=0.9483333333333335), mid=Score(precision=0.988, recall=0.97, fmeasure=0.9706666666666668), high=Score(precision=1.0, recall=0.9904999999999999, fmeasure=0.9893416666666667))}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "bleu_metric = load_metric(\"bleu\")\n",
    "meteor_metric = load_metric(\"meteor\")\n",
    "rouge_metric = load_metric(\"rouge\") \n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = bleu_metric.compute(predictions=[generated_answers], references=[[ground_truth_answers]])\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_score = meteor_metric.compute(predictions=generated_answers, references=ground_truth_answers)\n",
    "\n",
    "# Calculate ROUGE score\n",
    "rouge_score = rouge_metric.compute(predictions=generated_answers, references=ground_truth_answers)\n",
    "\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print(\"METEOR Score:\", meteor_score)\n",
    "print(\"ROUGE Score:\", rouge_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the best title for the passage?\n",
      "answer:  Djokovic's application for special permission to enter the United States\n"
     ]
    }
   ],
   "source": [
    "# trial implementation\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-race-QuestionAnswer\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-race-QuestionAnswer\")\n",
    "\n",
    "# context = r\"\"\"\n",
    "# World number one Novak Djokovic says he is hoping for a \"positive decision\" to allow him \n",
    "# to play at Indian Wells and the Miami Open next month. The United States has extended \n",
    "# its requirement for international visitors to be vaccinated against Covid-19. Proof of vaccination \n",
    "# will be required to enter the country until at least 10 April, but the Serbian has previously \n",
    "# said he is unvaccinated. The 35-year-old has applied for special permission to enter the country. \n",
    "# Indian Wells and the Miami Open - two of the most prestigious tournaments on the tennis calendar \n",
    "# outside the Grand Slams - start on 6 and 20 March respectively. Djokovic says he will return to \n",
    "# the ATP tour in Dubai next week after claiming a record-extending 10th Australian Open title \n",
    "# and a record-equalling 22nd Grand Slam men's title last month.\"\"\".replace(\"\\n\", \"\")\n",
    "\n",
    "# inputs = tokenizer(context, return_tensors=\"pt\")\n",
    "# outputs = model.generate(**inputs, max_length=100)\n",
    "# question_answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "# question_answer = question_answer.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
    "# question, answer = question_answer.split(tokenizer.sep_token)\n",
    "\n",
    "# print(\"question:\", question)\n",
    "# print(\"answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
