{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IkzDjVsLchP",
        "outputId": "feb686d7-7caa-43fc-d6aa-ec5b49b211f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import pipeline, set_seed, AutoTokenizer, AutoModelForCausalLM\n",
        "!pip install --upgrade huggingface_hub\n",
        "\n",
        "from huggingface_hub import login\n",
        "token = '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'\n",
        "login(token)\n",
        "!pip install openai\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCiCiKgjLd1b",
        "outputId": "ed4bd9fc-d8b4-40ce-95f1-4b0e029ba0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='chatcmpl-9IIbj055Qizp1HrVxE6dAgZae8bhs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1714148459, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=19, total_tokens=28))\n",
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(base_url=\"https://openai.vocareum.com/v1\", api_key='voc-10123831041165813220810661bf202916f59.11082931')\n",
        "completion = client.chat.completions.create(\n",
        " model=\"gpt-3.5-turbo\",\n",
        " messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        "\n",
        " )\n",
        "print(completion)\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4K_XTpVNLtMS"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('output_with_predictions_total.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z-C7W1UQL1O9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dataset[:150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GXAG35LML3zT"
      },
      "outputs": [],
      "source": [
        "# Define the prompt\n",
        "prompt = \"\"\"On a scale of 1 to 5, where 1 is completely\n",
        "incorrect and 5 is perfectly correct, rate the\n",
        "semantic relevance of the generated\n",
        "question. Generated question: \"{}\" and Ground truth question: \"{}\".\n",
        "\"\"\"\n",
        "\n",
        "# Example inputs\n",
        "generated_question = \"what is slate\"\n",
        "original_question = \"what rock is slate made from\"\n",
        "\n",
        "# Format the prompt with the example inputs\n",
        "prompt_instance = prompt.format(generated_question, original_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ModGsVYFL6ok",
        "outputId": "980a7fd5-874a-46c3-df74-24d70da0f847"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I would rate the semantic relevance of the generated question \"what is slate\" compared to the ground truth question \"what rock is slate made from\" as a 3 out of 5. The generated question is somewhat relevant as it touches on the topic of slate, but it does not directly address the specific inquiry regarding what rock slate is made from.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=\"gpt-3.5-turbo\"\n",
        "# Send prompt to OpenAI API\n",
        "response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who can score the semantic relevance of the generated_question, compared with original question.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{prompt_instance}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "predicted_text = response.choices[0].message.content\n",
        "predicted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0AUoowpTbc6",
        "outputId": "d858edb7-1501-4d2f-dbc7-bc97eeab87a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 1400/3626 [49:13<18:56:52, 30.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid or empty response at index 1399: ChatCompletion(id=None, choices=None, created=None, model=None, object=None, system_fingerprint=None, usage=None, error={'code': None, 'message': 'The request took longer to process than expected and has timed out', 'param': None, 'type': 'invalid_request_error'})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3626/3626 [2:01:06<00:00,  2.00s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming dataset, client, model, prompt, and grammar_scores are already defined\n",
        "grammar_scores = []\n",
        "\n",
        "for index, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
        "    generated_question = row['predicted_question']\n",
        "    original_question = row['question']\n",
        "    prompt_instance = prompt.format(generated_question, original_question)\n",
        "\n",
        "    try:\n",
        "        # Make a call to the model\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant who can score the semantic relevance of the generated_question, compared with original question.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"{prompt_instance}\"}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Check if response is not None and has the expected structure\n",
        "        if response and hasattr(response, 'choices') and response.choices and hasattr(response.choices[0], 'message') and response.choices[0].message:\n",
        "            scores = response.choices[0].message.content\n",
        "            grammar_scores.append(scores)\n",
        "        else:\n",
        "            print(f\"Invalid or empty response at index {index}: {response}\")\n",
        "            grammar_scores.append(None)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing response at index {index}: {e}\")\n",
        "        grammar_scores.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2cQOjmotxgtU"
      },
      "outputs": [],
      "source": [
        "grammar_scores_df = pd.DataFrame(grammar_scores)\n",
        "file_path = \"engl_S_Scores.csv\"\n",
        "grammar_scores_df.to_csv(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ScuoSKeV186V"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/engl_S_Scores.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3PoGgiLMKnc",
        "outputId": "00dacb46-2da4-4c6b-f97d-dd22ecc66123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                      0\n",
            "0     I would rate the semantic relevance of the gen...\n",
            "1     I would rate the semantic relevance of the gen...\n",
            "2     I would rate the semantic relevance of the gen...\n",
            "3     I would rate the semantic relevance of the gen...\n",
            "4     I would rate the semantic relevance of the gen...\n",
            "...                                                 ...\n",
            "3621  I would rate the generated question a 2 out of...\n",
            "3622  I would rate the semantic relevance of the gen...\n",
            "3623  I would rate the semantic relevance of the gen...\n",
            "3624  I would rate the semantic relevance of the gen...\n",
            "3625  I would rate the semantic relevance of the gen...\n",
            "\n",
            "[3626 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt48zJzX1x9w",
        "outputId": "b132ee07-7ad9-4b0c-a054-80dfad6ee698"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting scores: 100%|██████████| 3626/3626 [00:00<00:00, 120676.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       2.0\n",
            "1       2.0\n",
            "2       2.0\n",
            "3       2.0\n",
            "4       NaN\n",
            "       ... \n",
            "3621    2.0\n",
            "3622    2.0\n",
            "3623    1.0\n",
            "3624    1.0\n",
            "3625    1.0\n",
            "Name: score, Length: 3626, dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def extract_score(text):\n",
        "    if text is None:\n",
        "        return None\n",
        "    # Ensure the text is treated as a string\n",
        "    text = str(text)\n",
        "    match = re.search(r'(\\d+) out of 5', text)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Apply the function to each row in the dataframe's column '0'\n",
        "df['score'] = [extract_score(response) for response in tqdm(df['0'], desc=\"Extracting scores\")]\n",
        "\n",
        "print(df['score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8J-nd9l4FRI",
        "outputId": "297aa8ea-fc0d-4bac-a656-6a46ca21db04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average score: 2.265724857046754\n"
          ]
        }
      ],
      "source": [
        "# Extract scores into a separate list, excluding None and NaN values\n",
        "valid_scores = [score for score in df['score'] if pd.notna(score)]\n",
        "\n",
        "# Calculate the average score if there are any valid scores\n",
        "average_score = sum(valid_scores) / len(valid_scores) if valid_scores else None\n",
        "\n",
        "print(f\"Average score: {average_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRKnqgTkNN-s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
